{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDZmp2BO9KnQ"
   },
   "source": [
    "# **Laboratorio 12: 游 Despliegue 游**\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos</strong></center>\n",
    "\n",
    "### **Cuerpo Docente:**\n",
    "\n",
    "- Profesores: Ignacio Meza, Sebasti치n Tinoco\n",
    "- Auxiliar: Eduardo Moya\n",
    "- Ayudantes: Nicol치s Ojeda, Melanie Pe침a, Valentina Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdGqUgwX9pGQ"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados\n",
    "\n",
    "- Nombre de alumno 1: JUnwei He\n",
    "- Nombre de alumno 2: Sof칤a Ch치vez\n",
    "\n",
    "### **Link de repositorio de GitHub:** [Insertar Repositorio](https://github.com/sofiachavezb/LabProgramacionMDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YraSOKrf9yMl"
   },
   "source": [
    "## Temas a tratar\n",
    "\n",
    "- Entrenamiento y registro de modelos usando MLFlow.\n",
    "- Despliegue de modelo usando FastAPI\n",
    "- Containerizaci칩n del proyecto usando Docker\n",
    "\n",
    "## Reglas:\n",
    "\n",
    "- **Grupos de 2 personas**\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
    "- Prohibidas las copias.\n",
    "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
    "\n",
    "### Objetivos principales del laboratorio\n",
    "\n",
    "- Generar una soluci칩n a un problema a partir de ML\n",
    "- Desplegar su soluci칩n usando MLFlow, FastAPI y Docker\n",
    "\n",
    "El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D98okEzUE8hb"
   },
   "source": [
    "# **Introducci칩n**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSiuBfGiFlQM"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExODJnMHJzNzlkNmQweXoyY3ltbnZ2ZDlxY2c0aW5jcHNzeDNtOXBsdCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/AbPdhwsMgjMjax5reo/giphy.gif\" width=\"400\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPn8R-6u877j"
   },
   "source": [
    "\n",
    "\n",
    "Consumida en la tristeza el despido de Renac칤n, Smapina ha deca칤do en su desempe침o, lo que se ha traducido en un irregular tratamiento del agua. Esto ha implicado una baja en la calidad del agua, llegando a haber algunos puntos de la comuna en la que el vital elemento no es apto para el consumo humano. Es por esto que la sanitaria p칰blica de la municipalidad de Maip칰 se ha contactado con ustedes para que le entreguen una urgente soluci칩n a este problema (a la vez que dejan a Smapina, al igual que Renac칤n, sin trabajo 游땞).\n",
    "\n",
    "El problema que la empresa le ha solicitado resolver es el de elaborar un sistema que les permita saber si el agua es potable o no. Para esto, la sanitaria les ha proveido una base de datos con la lectura de m칰ltiples sensores IOT colocados en diversas ca침er칤as, conductos y estanques. Estos sensores se침alan nueve tipos de mediciones qu칤micas y m치s una etiqueta elaborada en laboratorio que indica si el agua es potable o no el agua.\n",
    "\n",
    "La idea final es que puedan, en el caso que el agua no sea potable, dar un aviso inmediato para corregir el problema. Tenga en cuenta que parte del equipo docente vive en Maip칰 y su intoxicaci칩n podr칤a implicar graves problemas para el cierre del curso.\n",
    "\n",
    "Atributos:\n",
    "\n",
    "1. pH value\n",
    "2. Hardness\n",
    "3. Solids (Total dissolved solids - TDS)\n",
    "4. Chloramines\n",
    "5. Sulfate\n",
    "6. Conductivity\n",
    "7. Organic_carbon\n",
    "8. Trihalomethanes\n",
    "9. Turbidity\n",
    "\n",
    "Variable a predecir:\n",
    "\n",
    "10. Potability (1 si es potable, 0 no potable)\n",
    "\n",
    "Descripci칩n de cada atributo se pueden encontrar en el siguiente link: [dataset](https://www.kaggle.com/adityakadiwal/water-potability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aIr6KegWsjS"
   },
   "source": [
    "# **1. Optimizaci칩n de modelos con Optuna + MLFlow (2.0 puntos)**\n",
    "\n",
    "El objetivo de esta secci칩n es que ustedes puedan combinar Optuna con MLFlow para poder realizar la optimizaci칩n de los hiperpar치metros de sus modelos.\n",
    "\n",
    "Como a칰n no hemos hablado nada sobre `MLFlow` cabe preguntarse: **춰쯈u칠 !\"#@ es `MLflow`?!**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media.tenor.com/eusgDKT4smQAAAAC/matthew-perry-chandler-bing.gif\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "## **MLFlow**\n",
    "\n",
    "`MLflow` es una plataforma de c칩digo abierto que simplifica la gesti칩n y seguimiento de proyectos de aprendizaje autom치tico. Con sus herramientas, los desarrolladores pueden organizar, rastrear y comparar experimentos, adem치s de registrar modelos y controlar versiones.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://spark.apache.org/images/mlflow-logo.png\" width=\"350\">\n",
    "</p>\n",
    "\n",
    "Si bien esta plataforma cuenta con un gran n칰mero de herramientas y funcionalidades, en este laboratorio trabajaremos con dos:\n",
    "1. **Runs**: Registro que constituye la informaci칩n guardada tras la ejecuci칩n de un entrenamiento. Cada `run` tiene su propio run_id, el cual sirve como identificador para el entrenamiento en s칤 mismo. Dentro de cada `run` podremos acceder a informaci칩n como los hiperpar치metros utilizados, las m칠tricas obtenidas, las librer칤as requeridas y hasta nos permite descargar el modelo entrenado.\n",
    "2. **Experiments**: Se utilizan para agrupar y organizar diferentes ejecuciones de modelos (`runs`). En ese sentido, un experimento puede agrupar 1 o m치s `runs`. De esta manera, es posible tambi칠n registrar m칠tricas, par치metros y archivos (artefactos) asociados a cada experimento.\n",
    "\n",
    "### **Todo bien pero entonces, 쯖칩mo se usa en la pr치ctica `MLflow`?**\n",
    "\n",
    "Es sencillo! Considerando un problema de machine learning gen칠rico, podemos registrar la informaci칩n relevante del entrenamiento ejecutando `mlflow.autolog()` antes entrenar nuestro modelo. Veamos este bonito ejemplo facilitado por los mismos creadores de `MLflow`:\n",
    "\n",
    "```python\n",
    "#!pip install mlflow\n",
    "import mlflow # importar mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# Create and train models.\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "\n",
    "mlflow.autolog() # registrar autom치ticamente informaci칩n del entrenamiento\n",
    "with mlflow.start_run(): #맋elimita inicio y fin del run\n",
    "    #마qu칤 comienza el run\n",
    "    rf.fit(X_train, y_train) # train the model\n",
    "    predictions = rf.predict(X_test) # Use the model to make predictions on the test dataset.\n",
    "    # aqu칤 termina el run\n",
    "```\n",
    "\n",
    "Si ustedes ejecutan el c칩digo anterior en sus m치quinas locales (desde un jupyter notebook por ejemplo) se dar치n cuenta que en su directorio *root* se ha creado la carpeta `mlruns`. Esta carpeta lleva el tracking de todos los entrenamientos ejecutados desde el directorio root (importante: si se cambian de directorio y vuelven a ejecutar el c칩digo anterior, se crear치 otra carpeta y no tendr치n acceso al entrenamiento anterior). Para visualizar estos entrenamientos, `MLflow` nos facilita hermosa interfaz visual a la que podemos acceder ejecutando:\n",
    "\n",
    "```\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "y luego pinchando en la ruta http://127.0.0.1:5000 que nos retorna la terminal. Veamos en vivo algunas de sus funcionalidades!\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExZXVuM3A5MW1heDFpa21qbGlwN2pyc2VoNnZsMmRzODZxdnluemo2bCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3o84sq21TxDH6PyYms/giphy.gif\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Les dejamos tambi칠n algunos comandos 칰tiles:\n",
    "\n",
    "- `mlflow.create_experiment(\"nombre_experimento\")`: Les permite crear un nuevo experimento para agrupar entrenamientos\n",
    "- `mlflow.log_metric(\"nombre_m칠trica\", m칠trica)`: Les permite registrar una m칠trica *custom* bajo el nombre de \"nombre_m칠trica\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptP_ygr7S04t"
   },
   "source": [
    "## **1.1 Combinando Optuna + MLflow (2.0 puntos)**\n",
    "\n",
    "Ahora que tenemos conocimiento de ambas herramientas, intentemos ahora combinarlas para **m치s sabor**. El objetivo de este apartado es simple: automatizar la optimizaci칩n de los par치metros de nuestros modelos usando `Optuna` y registrando de forma autom치tica cada resultado en `MLFlow`.\n",
    "\n",
    "Considerando el objetivo planteado, se le pide completar la funci칩n `optimize_model`, la cual debe:\n",
    "- **Optimizar los hiperpar치metros del modelo `XGBoost` usando `Optuna`.**\n",
    "- **Registrar cada entrenamiento en un experimento nuevo**, asegur치ndose de que la m칠trica `f1-score` se registre como `\"valid_f1\"`. No se deben guardar todos los experimentos en *Default*; en su lugar, cada `experiment` y `run` deben tener nombres interpretables, reconocibles y diferentes a los nombres por defecto (por ejemplo, para un run: \"XGBoost con lr 0.1\").\n",
    "- **Guardar los gr치ficos de Optuna** dentro de una carpeta de artefactos de Mlflow llamada `/plots`.\n",
    "- **Devolver el mejor modelo** usando la funci칩n `get_best_model` y serializarlo en el disco con `pickle.dump`. Luego, guardar el modelo en la carpeta `/models`.\n",
    "- **Guardar el c칩digo en `optimize.py`**. La ejecuci칩n de `python optimize.py` deber칤a ejecutar la funci칩n `optimize_model`.\n",
    "- **Guardar las versiones de las librer칤as utilizadas** en el desarrollo.\n",
    "- **Respalde las configuraciones del modelo final y la importancia de las variables** en un gr치fico dentro de la carpeta `/plots` creada anteriormente.\n",
    "\n",
    "*Hint: Le puede ser 칰til revisar los par치metros que recibe `mlflow.start_run`*\n",
    "\n",
    "```python\n",
    "def get_best_model(experiment_id):\n",
    "    runs = mlflow.search_runs(experiment_id)\n",
    "    best_model_id = runs.sort_values(\"metrics.valid_f1\")[\"run_id\"].iloc[0]\n",
    "    best_model = mlflow.sklearn.load_model(\"runs:/\" + best_model_id + \"/model\")\n",
    "\n",
    "    return best_model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "bAse7L3bb8an",
    "outputId": "65934f10-1079-4ff7-84b6-9e00c6fc19ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: mlflow-skinny==2.18.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow) (2.18.0)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow) (1.14.0)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<3 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow) (2.0.2)\n",
      "Requirement already satisfied: pandas<3 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<19,>=4.0.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow) (18.1.0)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow) (1.5.2)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow) (1.13.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow) (2.0.36)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: waitress<4 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.0)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (0.38.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
      "Requirement already satisfied: packaging<25 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (24.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (5.29.0)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from mlflow-skinny==2.18.0->mlflow) (0.5.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.6)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (308)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from graphene<4->mlflow) (3.2.5)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==2.18.0->mlflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth~=2.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (2.36.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.2.15)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (0.49b2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (2024.8.30)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.17.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.6.1)\n",
      "Requirement already satisfied: optuna in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from optuna) (1.14.0)\n",
      "Requirement already satisfied: colorlog in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from optuna) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from optuna) (2.0.36)\n",
      "Requirement already satisfied: tqdm in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.6)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Requirement already satisfied: kaleido in c:\\users\\fcb11\\labprog\\repo\\.venv\\lib\\site-packages (0.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow\n",
    "!pip install optuna\n",
    "!pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "m-wmFp1AcPa_",
    "outputId": "506edf99-802e-4e95-d6b2-d2e278692c2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Potability\n",
       "0    1998\n",
       "1    1278\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\"water_potability.csv\")\n",
    "y = df.pop(\"Potability\")\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MQaOAirehEOo"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qZuGSzmLpd5U"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fcb11\\LabProg\\repo\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "EXPERIMENT_NAME = \"XGBoost_Optimization\"\n",
    "PLOTS_DIR = \"plots\"\n",
    "MODELS_DIR = \"models\"\n",
    "\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "def format_params_for_run_name(params):\n",
    "    \"\"\"Formatea los par치metros en un string compacto para el nombre del run.\"\"\"\n",
    "    return \"_\".join([f\"{k}-{v}\" for k, v in params.items()])\n",
    "\n",
    "def objective(trial, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Funci칩n objetivo para Optuna.\"\"\"\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 10.0),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 10.0),\n",
    "    }\n",
    "\n",
    "    # Entrenamiento del modelo\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "    # Predicciones y c치lculo de la m칠trica\n",
    "    y_pred = model.predict(X_test)\n",
    "    valid_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Registrar la m칠trica\n",
    "    mlflow.log_metric(\"valid_f1\", valid_f1)\n",
    "\n",
    "    return valid_f1\n",
    "\n",
    "def optimize_model(X_train, y_train, X_test, y_test, n_trials=10):\n",
    "    \"\"\"Optimiza los hiperpar치metros del modelo XGBoost y registra los resultados en MLFlow.\"\"\"\n",
    "    # Configurar el experimento 칰nico\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", study_name=EXPERIMENT_NAME)\n",
    "\n",
    "    def mlflow_objective(trial):\n",
    "        params = {\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        }\n",
    "        run_name = f\"Run_XGBoost_{format_params_for_run_name(params)}\"\n",
    "\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            mlflow.log_params(params)\n",
    "            return objective(trial, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    study.optimize(mlflow_objective, n_trials=n_trials)\n",
    "\n",
    "    # Guardar resultados del estudio\n",
    "    best_params = study.best_params\n",
    "    best_model = xgb.XGBClassifier(**best_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    model_name = 'XGBoost_'+format_params_for_run_name(best_params)\n",
    "    model_path = f\"{MODELS_DIR}/model_{model_name}.pkl\"\n",
    "\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    mlflow.sklearn.log_model(best_model, artifact_path=f\"model_{model_name}\")\n",
    "\n",
    "    # Importancia de variables\n",
    "    feature_importances_path = f\"{PLOTS_DIR}/feature_importances_{model_name}.png\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(X_train.columns, best_model.feature_importances_, color='thistle')\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.title(\"Feature Importances\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(feature_importances_path)\n",
    "    mlflow.log_artifact(feature_importances_path, artifact_path=\"plots\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Experiment '{EXPERIMENT_NAME}' completed. Best model saved as {model_path}.\")\n",
    "\n",
    "    return best_model\n",
    "def get_best_model():\n",
    "    \"\"\"Carga y devuelve el mejor modelo guardado.\"\"\"\n",
    "    model_path = f\"{MODELS_DIR}/best_model.pkl\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        best_model = pickle.load(f)\n",
    "    return best_model\n",
    "\n",
    "def save_library_versions():\n",
    "    \"\"\"Guarda las versiones de las librer칤as utilizadas.\"\"\"\n",
    "    versions = {\n",
    "        \"optuna\": optuna.__version__,\n",
    "        \"mlflow\": mlflow.__version__,\n",
    "        \"xgboost\": xgb.__version__,\n",
    "        \"matplotlib\": plt.matplotlib.__version__,\n",
    "    }\n",
    "    with open(f\"{MODELS_DIR}/library_versions.json\", \"w\") as f:\n",
    "        json.dump(versions, f)\n",
    "    mlflow.log_artifact(f\"{MODELS_DIR}/library_versions.json\", artifact_path=\"configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jV2hEQE4ohBE",
    "outputId": "c6a36da7-ed5e-44dd-ae45-696f3400351f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' best_model = optimize_model(X_train, y_train, X_test, y_test)\\nsave_library_versions()\\nprint(\"Optimization completed.\") '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" best_model = optimize_model(X_train, y_train, X_test, y_test)\n",
    "save_library_versions()\n",
    "print(\"Optimization completed.\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYm67Ohdrgas",
    "outputId": "d077f8f0-48c2-4cf1-8eb3-9c0d763c2578"
   },
   "outputs": [],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tL2iG18289j9"
   },
   "source": [
    "# **2. FastAPI (2.0 puntos)**\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://media3.giphy.com/media/YQitE4YNQNahy/giphy-downsized-large.gif\" width=\"500\">\n",
    "</div>\n",
    "\n",
    "Con el modelo ya entrenado, la idea de esta secci칩n es generar una API REST a la cual se le pueda hacer *requests* para as칤 interactuar con su modelo. En particular, se le pide:\n",
    "\n",
    "- Guardar el c칩digo de esta secci칩n en el archivo `main.py`. Note que ejecutar `python main.py` deber칤a levantar el servidor en el puerto por defecto.\n",
    "- Defina `GET` con ruta tipo *home* que describa brevemente su modelo, el problema que intenta resolver, su entrada y salida.\n",
    "- Defina un `POST` a la ruta `/potabilidad/` donde utilice su mejor optimizado para predecir si una medici칩n de agua es o no potable. Por ejemplo, una llamada de esta ruta con un *body*:\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"ph\":10.316400384553162,\n",
    "   \"Hardness\":217.2668424334475,\n",
    "   \"Solids\":10676.508475429378,\n",
    "   \"Chloramines\":3.445514571005745,\n",
    "   \"Sulfate\":397.7549459751925,\n",
    "   \"Conductivity\":492.20647361771086,\n",
    "   \"Organic_carbon\":12.812732207582542,\n",
    "   \"Trihalomethanes\":72.28192021570328,\n",
    "   \"Turbidity\":3.4073494284238364\n",
    "}\n",
    "```\n",
    "\n",
    "Su servidor deber칤a retornar una respuesta HTML con c칩digo 200 con:\n",
    "\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"potabilidad\": 0 # respuesta puede variar seg칰n el clasificador que entrenen\n",
    "}\n",
    "```\n",
    "\n",
    "**`HINT:` Recuerde que puede utilizar [http://localhost:8000/docs](http://localhost:8000/docs) para hacer un `POST`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSausqDJ9CQh"
   },
   "source": [
    "# **3. Docker (2 puntos)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNmC483flS00"
   },
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*9rafh2W0rbRJIKJzqYc8yA.gif\" width=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "niMA_qsCjqlv"
   },
   "source": [
    "Tras el 칠xito de su aplicaci칩n web para generar la salida, Smapina le solicita que genere un contenedor para poder ejecutarla en cualquier computador de la empresa de agua potable.\n",
    "\n",
    "## **3.1 Creaci칩n de Container (1 punto)**\n",
    "\n",
    "Cree un Dockerfile que use una imagen base de Python, copie los archivos del proyecto e instale las dependencias desde un `requirements.txt`. Con esto, construya y ejecute el contenedor Docker para la API configurada anteriormente. Entregue el c칩digo fuente (incluyendo `main.py`, `requirements.txt`, y `Dockerfile`) y la imagen Docker de la aplicaci칩n. Para la dockerizaci칩n, aseg칰rese de cumplir con los siguientes puntos:\n",
    "\n",
    "1. **Generar un archivo `.dockerignore`** que ignore carpetas y archivos innecesarios dentro del contenedor.\n",
    "2. **Configurar un volumen** que permita la persistencia de los datos en una ruta local del computador.\n",
    "3. **Exponer el puerto** para acceder a la ruta de la API sin tener que entrar al contenedor directamente.\n",
    "4. **Incluir im치genes en el notebook** que muestren la ejecuci칩n del contenedor y los resultados obtenidos.\n",
    "5. **Revisar y comentar los recursos utilizados por el contenedor**. Analice si los contenedores son livianos en t칠rminos de recursos.\n",
    "\n",
    "## **3.2 Preguntas de Smapina (1 punto)**\n",
    "Tras haber experimentado con Docker, Smapina desea profundizar m치s en el tema y decide realizarle las siguientes consultas:\n",
    "\n",
    "- 쮺칩mo se diferencia Docker de una m치quina virtual (VM)?\n",
    "- 쮺u치l es la diferencia entre usar Docker y ejecutar la aplicaci칩n directamente en el sistema local?\n",
    "- 쮺칩mo asegura Docker la consistencia entre diferentes entornos de desarrollo y producci칩n?\n",
    "- 쮺칩mo se gestionan los vol칰menes en Docker para la persistencia de datos?\n",
    "- 쯈u칠 son Dockerfile y docker-compose.yml, y cu치l es su prop칩sito?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GwP2aLT9C1l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xJ_ZK1IfnZW"
   },
   "source": [
    "# Conclusi칩n\n",
    "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://i.pinimg.com/originals/84/5d/f1/845df1aefc6a5e37ae575327a0cc6e43.gif\" width=\"500\">\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
